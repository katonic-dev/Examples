{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63da9664-b803-4a52-80fe-683b144f32b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, recall_score, f1_score, precision_score\n",
    "import mlflow\n",
    "from katonic.ml import MyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "979f13ac-5420-4384-85d0-2041727cab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "myclient = MyClient()\n",
    "mlflow = myclient.mlflow\n",
    "client = myclient.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "750ef618-492a-48c9-9a73-b8349494afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(actual, pred):\n",
    "    acc_score = accuracy_score(actual, pred)\n",
    "    recall = recall_score(actual, pred, average='weighted')\n",
    "    precision_scr = precision_score(actual, pred, average='weighted')\n",
    "    f1_scr = f1_score(actual, pred, average='weighted')\n",
    "    \n",
    "    return (\n",
    "        acc_score,\n",
    "        recall,\n",
    "        f1_scr,\n",
    "        precision_scr\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cbc0904-4ecc-425d-bc55-3805a8206400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/10/25 04:18:09 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of lightgbm. If you encounter errors during autologging, try upgrading / downgrading lightgbm to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: average\n",
      "[LightGBM] [Warning] Unknown parameter: average\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000031 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89\n",
      "[LightGBM] [Info] Number of data points in the train set: 120, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -1.176574\n",
      "[LightGBM] [Info] Start training from score -1.049822\n",
      "[LightGBM] [Info] Start training from score -1.073920\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: average\n",
      "[LightGBM] [Warning] Unknown parameter: average\n"
     ]
    }
   ],
   "source": [
    "mlflow.lightgbm.autolog()\n",
    "exp_name = \"mlflow-test-lightbgm\"\n",
    "mlflow.set_experiment(exp_name)\n",
    "exp_details = mlflow.get_experiment_by_name(exp_name)\n",
    "\n",
    "data = load_iris()\n",
    "feature_names = [\n",
    "    name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    for name in data[\"feature_names\"]\n",
    "]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[\"data\"], data[\"target\"], test_size=0.2\n",
    ")\n",
    "\n",
    "with mlflow.start_run(run_name=exp_name):\n",
    "    lgb_classifier = LGBMClassifier(\n",
    "        n_estimators=10,\n",
    "        max_depth=3,\n",
    "        learning_rate=1,\n",
    "        #objective=\"binary:logistic\",\n",
    "        random_state=123,\n",
    "        average='weighted'\n",
    "    )\n",
    "    lgb_classifier.fit(X_train, y_train)\n",
    "    y_pred = lgb_classifier.predict(X_test)\n",
    "    (acc_score, recall, f1_scr, precision_scr) = metric(y_test, y_pred)\n",
    "\n",
    "    model_metrics = {\n",
    "        \"accuracy_score\": acc_score,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1_scr,\n",
    "        \"precision_score\": precision_scr\n",
    "    }\n",
    "\n",
    "    for metric_name, score in model_metrics.items():\n",
    "        mlflow.log_metric(metric_name, score)\n",
    "\n",
    "    model_info = mlflow.lightgbm.log_model(lgb_model=lgb_classifier, artifact_path=\"model\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1280bc4-f23a-4c56-b6e2-f2bb7616acc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff291ae6-77cb-47cc-9761-4388f72d1b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
