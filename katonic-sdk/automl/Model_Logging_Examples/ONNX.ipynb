{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63da9664-b803-4a52-80fe-683b144f32b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from katonic.ml import MyClient\n",
    "import numpy as np\n",
    "from skl2onnx import to_onnx\n",
    "import onnxruntime as rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "979f13ac-5420-4384-85d0-2041727cab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "myclient = MyClient()\n",
    "mlflow = myclient.mlflow\n",
    "client = myclient.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "750ef618-492a-48c9-9a73-b8349494afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(actual, pred):\n",
    "    acc_score = accuracy_score(actual, pred)\n",
    "    recall = recall_score(actual, pred, average='weighted')\n",
    "    precision_scr = precision_score(actual, pred, average='weighted')\n",
    "    f1_scr = f1_score(actual, pred, average='weighted')\n",
    "    \n",
    "    return (\n",
    "        acc_score,\n",
    "        recall,\n",
    "        f1_scr,\n",
    "        precision_scr\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cbc0904-4ecc-425d-bc55-3805a8206400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "exp_name = \"mlflow-test-onnx\"\n",
    "mlflow.set_experiment(exp_name)\n",
    "exp_details = mlflow.get_experiment_by_name(exp_name)\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X = X.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "clr = RandomForestClassifier()\n",
    "clr.fit(X_train, y_train)\n",
    "\n",
    "with mlflow.start_run(run_name=exp_name):\n",
    "    onx = to_onnx(clr, X[:1])\n",
    "    with open(\"rf_iris.onnx\", \"wb\") as f:\n",
    "        f.write(onx.SerializeToString())\n",
    "        \n",
    "    sess = rt.InferenceSession(\"rf_iris.onnx\", providers=[\"CPUExecutionProvider\"])\n",
    "    input_name = sess.get_inputs()[0].name\n",
    "    label_name = sess.get_outputs()[0].name\n",
    "    pred_onx = sess.run([label_name], {input_name: X_test.astype(np.float32)})[0]\n",
    "\n",
    "    (acc_score, recall, f1_scr, precision_scr) = metric(y_test, pred_onx)\n",
    "\n",
    "    model_metrics = {\n",
    "        \"accuracy_score\": acc_score,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1_scr,\n",
    "        \"precision_score\": precision_scr\n",
    "    }\n",
    "    \n",
    "    for metric_name, score in model_metrics.items():\n",
    "        mlflow.log_metric(metric_name, score)\n",
    "\n",
    "    model_info = mlflow.onnx.log_model(onnx_model=onx, artifact_path=\"model\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7eb045-29a7-459a-b782-1d4aedb5ff4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
